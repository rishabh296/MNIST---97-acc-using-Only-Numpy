{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "timer = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(path+'train_image.csv', header=None).values\n",
    "Y_train = pd.read_csv(path+'train_label.csv', header=None).values\n",
    "X_test = pd.read_csv(path+'test_image.csv', header=None).values\n",
    "Y_test = pd.read_csv(path+'test_label.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = genfromtxt(path+'train_image.csv', delimiter=',')\n",
    "# Y_train = genfromtxt(path+'train_label.csv', delimiter=',')\n",
    "# X_test = genfromtxt(path+'test_image.csv', delimiter=',')\n",
    "# Y_test = genfromtxt(path+'test_label.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding train labels\n",
    "classes = 10\n",
    "num = Y_train.shape[0]\n",
    "Y_train = Y_train.reshape(1, num)\n",
    "Y_train = np.eye(classes)[Y_train.astype('int32')]\n",
    "Y_train = Y_train.T.reshape(classes, num)\n",
    "\n",
    "# one-hot encoding train labels\n",
    "num = Y_test.shape[0]\n",
    "Y_test = Y_test.reshape(1, num)\n",
    "Y_test = np.eye(classes)[Y_test.astype('int32')]\n",
    "Y_test = Y_test.T.reshape(classes, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def dReLU(x):\n",
    "    return 1*(x>0)\n",
    "\n",
    "def compute_loss(Y, Y_hat):\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    L = -(1/Y.shape[1]) * L_sum\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, params):\n",
    "    \n",
    "    cache = {}\n",
    "\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "    cache[\"A1\"] = relu(cache[\"Z1\"])\n",
    "    \n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
    "#     cache[\"Z2\"]/=255.0\n",
    "    cache[\"A2\"] = relu(cache[\"Z2\"])\n",
    "    \n",
    "    cache[\"Z3\"] = np.matmul(params[\"W3\"], cache[\"A2\"]) + params[\"b3\"]\n",
    "    cache[\"A3\"] = np.exp(cache[\"Z3\"]) / np.sum(np.exp(cache[\"Z3\"]), axis=0)\n",
    "\n",
    "    return cache\n",
    "\n",
    "def back_propagate(X, Y, params, cache, m):\n",
    "    \n",
    "    dZ3 = cache[\"A3\"] - Y\n",
    "    dW3 = (1/m) * np.matmul(dZ3, cache[\"A2\"].T)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "\n",
    "    dA2 = np.matmul(params[\"W3\"].T, dZ3)\n",
    "#     dZ2 = dA2 * sigmoid(cache[\"Z2\"]) * (1 - sigmoid(cache[\"Z2\"]))\n",
    "    dZ2 = dA2 * dReLU(cache[\"Z2\"])\n",
    "    dW2 = (1/m) * np.matmul(dZ2, cache['A1'].T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
    "#     dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "    dZ1 = dA1 * dReLU(cache[\"Z1\"])\n",
    "    dW1 = (1/m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2, \"dW3\": dW3, \"db3\": db3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier(n_cur,n_prev):\n",
    "    return np.sqrt(6/(n_cur+n_prev))\n",
    "def kaiming(n_prev):\n",
    "    return np.sqrt(2/n_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = X_train.shape[0]\n",
    "n_h1 = 128\n",
    "n_h2 = 128\n",
    "# initialization\n",
    "init1 = xavier(n_h1, n_x)\n",
    "init2 = xavier(n_h2,n_h1)\n",
    "init3 = xavier(classes,n_h2)\n",
    "\n",
    "params = {\"W1\": np.random.randn(n_h1, n_x) * 0.01,\"b1\": np.zeros((n_h1, 1)),\n",
    "          \"W2\": np.random.randn(n_h2, n_h1) * 0.01,\"b2\": np.zeros((n_h2, 1)),\n",
    "          \"W3\": np.random.randn(classes, n_h2) * 0.01,\"b3\": np.zeros((classes, 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "beta = 0.85 #momentum\n",
    "lr = 0.01 #learning rate\n",
    "batches = int(np.ceil(X_train.shape[1]/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 0.1394328612642224\n",
      "Epoch 2: training loss = 0.08765555420472494\n",
      "Epoch 3: training loss = 0.07725672761648951\n",
      "Epoch 4: training loss = 0.06280135611328559\n",
      "Epoch 5: training loss = 0.045084621559952506\n",
      "Epoch 6: training loss = 0.056319887814142044\n",
      "Epoch 7: training loss = 0.03374082094558189\n",
      "Epoch 8: training loss = 0.026228804788225184\n",
      "Epoch 9: training loss = 0.04102899172221208\n",
      "Epoch 10: training loss = 0.02244475603344319\n",
      "Epoch 11: training loss = 0.0257766899946393\n",
      "Epoch 12: training loss = 0.023012051844750886\n",
      "Epoch 13: training loss = 0.015060984721757195\n",
      "Epoch 14: training loss = 0.01980176322197511\n",
      "Epoch 15: training loss = 0.024690482498565352\n",
      "Epoch 16: training loss = 0.011018727922597999\n",
      "Epoch 17: training loss = 0.008117709753188243\n",
      "Epoch 18: training loss = 0.01586675375062442\n",
      "Epoch 19: training loss = 0.011435696327844034\n",
      "Epoch 20: training loss = 0.009911402620447637\n",
      "Time taken for Predictions -  1.1233383019765217\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "backup = []\n",
    "for i in range(epochs):\n",
    "    \n",
    "    dW1, db1 = 0, 0\n",
    "    dW2, db2 = 0, 0\n",
    "    dW3, db3 = 0, 0\n",
    "    \n",
    "#     if i>12:\n",
    "#         lr = 0.001\n",
    "    \n",
    "    for j in range(batches):\n",
    "\n",
    "        a = j * batch_size\n",
    "        b = min(a+batch_size, X_train.shape[1]-1)\n",
    "        X = X_train[:, a:b]\n",
    "        Y = Y_train[:, a:b]\n",
    "        m = b-a\n",
    "\n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache, m)\n",
    "        \n",
    "        dW1 = (beta * dW1 + (1 - beta) * grads[\"dW1\"])\n",
    "        db1 = (beta * db1 + (1 - beta) * grads[\"db1\"])\n",
    "        dW2 = (beta * dW2 + (1 - beta) * grads[\"dW2\"])\n",
    "        db2 = (beta * db2 + (1 - beta) * grads[\"db2\"])\n",
    "        dW3 = (beta * dW3 + (1 - beta) * grads[\"dW3\"])\n",
    "        db3 = (beta * db3 + (1 - beta) * grads[\"db3\"])\n",
    "\n",
    "        # gradient descent\n",
    "        params[\"W1\"] = params[\"W1\"] - lr * dW1\n",
    "        params[\"b1\"] = params[\"b1\"] - lr * db1\n",
    "        params[\"W2\"] = params[\"W2\"] - lr * dW2\n",
    "        params[\"b2\"] = params[\"b2\"] - lr * db2\n",
    "        params[\"W3\"] = params[\"W3\"] - lr * dW3\n",
    "        params[\"b3\"] = params[\"b3\"] - lr * db3\n",
    "\n",
    "    # forward pass on training set\n",
    "    backup = feed_forward(X_train, params)\n",
    "    train_loss = compute_loss(Y_train, backup[\"A3\"])\n",
    "    cache = feed_forward(X_test, params)\n",
    "#     test_loss = compute_loss(Y_test, cache[\"A3\"])\n",
    "    \n",
    "    print(\"Epoch {}: training loss = {}\".format(i + 1, train_loss))\n",
    "print('Time taken for Predictions - ',(time.time()-t)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy -  99.66\n",
      "Test Accuracy -  98.01\n",
      "Train Size -  60000  Test Size -  10000\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy - ',np.sum(np.argmax(backup['A3'],axis=0) == np.argmax(Y_train,axis=0))/(Y_train.shape[1]/100))\n",
    "print('Test Accuracy - ',np.sum(np.argmax(cache['A3'],axis=0) == np.argmax(Y_test,axis=0))/(Y_test.shape[1]/100))\n",
    "print('Train Size - ',Y_train.shape[1], ' Test Size - ',cache['A3'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken -  1124.0676889419556\n"
     ]
    }
   ],
   "source": [
    "df = {'predictions':np.argmax(cache['A3'], axis=0)}\n",
    "df2 = pd.DataFrame(data=df)\n",
    "df2.to_csv(path+'test_predictions.csv', header=None, index=None)\n",
    "print('Time taken - ',time.time()-timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(path+'test_predictions.csv', np.argmax(cache['A3'], axis=0), fmt='%i', delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
